{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:16.614224Z",
     "iopub.status.busy": "2021-09-25T01:39:16.613637Z",
     "iopub.status.idle": "2021-09-25T01:39:23.084012Z",
     "shell.execute_reply": "2021-09-25T01:39:23.083279Z",
     "shell.execute_reply.started": "2021-09-25T01:39:16.614189Z"
    },
    "papermill": {
     "duration": 2.094537,
     "end_time": "2021-08-04T01:25:18.881487",
     "exception": false,
     "start_time": "2021-08-04T01:25:16.78695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "import timm\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:16.60086Z",
     "iopub.status.busy": "2021-09-25T01:39:16.600379Z",
     "iopub.status.idle": "2021-09-25T01:39:16.612052Z",
     "shell.execute_reply": "2021-09-25T01:39:16.611405Z",
     "shell.execute_reply.started": "2021-09-25T01:39:16.600826Z"
    },
    "papermill": {
     "duration": 0.04513,
     "end_time": "2021-08-04T01:25:16.683443",
     "exception": false,
     "start_time": "2021-08-04T01:25:16.638313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    apex=False\n",
    "    debug=False\n",
    "    print_freq=10\n",
    "    num_workers=0\n",
    "    size=224\n",
    "    model_name='vit_large_patch32_224'\n",
    "    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    epochs=0\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=3 # CosineAnnealingLR\n",
    "    #T_0=3 # CosineAnnealingWarmRestarts\n",
    "    lr=1e-4\n",
    "    min_lr=1e-6\n",
    "    batch_size=32\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed = [42] #[42, 10, 20, 51, 111]\n",
    "    target_size=1\n",
    "    target_col='KIc'\n",
    "    n_fold=5\n",
    "    kfold=\"Kfold\" #or Kfold\n",
    "    trn_fold = [i for i in range(n_fold)]\n",
    "    train=True\n",
    "    grad_cam=True\n",
    "      \n",
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './KIc/Model/vit/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:30.703234Z",
     "iopub.status.busy": "2021-09-25T01:39:30.7011Z",
     "iopub.status.idle": "2021-09-25T01:39:30.720295Z",
     "shell.execute_reply": "2021-09-25T01:39:30.719608Z",
     "shell.execute_reply.started": "2021-09-25T01:39:30.703189Z"
    },
    "papermill": {
     "duration": 0.078664,
     "end_time": "2021-08-04T01:25:27.284121",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.205457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "    return score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:30.793168Z",
     "iopub.status.busy": "2021-09-25T01:39:30.79291Z",
     "iopub.status.idle": "2021-09-25T01:39:30.812349Z",
     "shell.execute_reply": "2021-09-25T01:39:30.81166Z",
     "shell.execute_reply.started": "2021-09-25T01:39:30.793134Z"
    },
    "papermill": {
     "duration": 0.045394,
     "end_time": "2021-08-04T01:25:27.976623",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.931229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['file_path'].values\n",
    "        self.labels = df[CFG.target_col].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_names[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:30.817111Z",
     "iopub.status.busy": "2021-09-25T01:39:30.81621Z",
     "iopub.status.idle": "2021-09-25T01:39:30.826076Z",
     "shell.execute_reply": "2021-09-25T01:39:30.82545Z",
     "shell.execute_reply.started": "2021-09-25T01:39:30.817076Z"
    },
    "papermill": {
     "duration": 0.04224,
     "end_time": "2021-08-04T01:25:28.202021",
     "exception": false,
     "start_time": "2021-08-04T01:25:28.159781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            # A.Resize(CFG.size, CFG.size),\n",
    "            A.RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.size, CFG.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:31.974121Z",
     "iopub.status.busy": "2021-09-25T01:39:31.973801Z",
     "iopub.status.idle": "2021-09-25T01:39:31.981565Z",
     "shell.execute_reply": "2021-09-25T01:39:31.980845Z",
     "shell.execute_reply.started": "2021-09-25T01:39:31.974083Z"
    },
    "papermill": {
     "duration": 0.072697,
     "end_time": "2021-08-04T01:25:29.305374",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.232677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained)\n",
    "        self.n_features = self.model.head.in_features\n",
    "        self.model.head = nn.Identity()\n",
    "        self.fc = nn.Linear(self.n_features, self.cfg.target_size)\n",
    "\n",
    "    def feature(self, image):\n",
    "        feature = self.model(image)\n",
    "        return feature\n",
    "        \n",
    "    def forward(self, image):\n",
    "        feature = self.feature(image)\n",
    "        output = self.fc(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:31.983208Z",
     "iopub.status.busy": "2021-09-25T01:39:31.982737Z",
     "iopub.status.idle": "2021-09-25T01:39:31.992378Z",
     "shell.execute_reply": "2021-09-25T01:39:31.991645Z",
     "shell.execute_reply.started": "2021-09-25T01:39:31.983173Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Loss\n",
    "# ====================================================\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:31.99414Z",
     "iopub.status.busy": "2021-09-25T01:39:31.993855Z",
     "iopub.status.idle": "2021-09-25T01:39:32.01968Z",
     "shell.execute_reply": "2021-09-25T01:39:32.018923Z",
     "shell.execute_reply.started": "2021-09-25T01:39:31.994085Z"
    },
    "papermill": {
     "duration": 0.112331,
     "end_time": "2021-08-04T01:25:29.638305",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.525974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    if CFG.apex:#使わないところは消す\n",
    "        scaler = GradScaler()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if CFG.apex:\n",
    "            with autocast():\n",
    "                y_preds = model(images)\n",
    "                loss = criterion(y_preds.view(-1), labels)\n",
    "        else:\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds.view(-1), labels)\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            if CFG.apex:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds.view(-1), labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:32.035336Z",
     "iopub.status.busy": "2021-09-25T01:39:32.035065Z",
     "iopub.status.idle": "2021-09-25T01:39:32.055932Z",
     "shell.execute_reply": "2021-09-25T01:39:32.055078Z",
     "shell.execute_reply.started": "2021-09-25T01:39:32.035295Z"
    },
    "papermill": {
     "duration": 0.075124,
     "end_time": "2021-08-04T01:25:30.031874",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.95675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold, seed):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[CFG.target_col].values\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='train'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size * 2, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, pretrained=True)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = RMSELoss()\n",
    "\n",
    "    best_score = np.inf\n",
    "    best_loss = np.inf\n",
    "\n",
    "    # for epoch in range(CFG.epochs):\n",
    "        # eval\n",
    "    avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "    \n",
    "    if isinstance(scheduler, ReduceLROnPlateau):\n",
    "        scheduler.step(avg_val_loss)\n",
    "    elif isinstance(scheduler, CosineAnnealingLR):\n",
    "        scheduler.step()\n",
    "    elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "        scheduler.step()\n",
    "\n",
    "    # scoring\n",
    "    # score = get_score(valid_labels, preds)\n",
    "\n",
    "    # if score < best_score:\n",
    "    #     best_score = score\n",
    "    #     LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "    torch.save({'model': model.state_dict(), 'preds': preds}, OUTPUT_DIR+f'{CFG.model_name}_{CFG.kfold}_fold{fold}_seed{seed}_best_netweight.pth')\n",
    "    \n",
    "    valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_{CFG.kfold}_fold{fold}_seed{seed}_best_netweight.pth', \n",
    "                                map_location=torch.device('cpu'))['preds']\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:32.057783Z",
     "iopub.status.busy": "2021-09-25T01:39:32.057505Z",
     "iopub.status.idle": "2021-09-25T01:39:32.077182Z",
     "shell.execute_reply": "2021-09-25T01:39:32.076545Z",
     "shell.execute_reply.started": "2021-09-25T01:39:32.057752Z"
    },
    "papermill": {
     "duration": 0.073141,
     "end_time": "2021-08-04T01:25:30.156241",
     "exception": false,
     "start_time": "2021-08-04T01:25:30.0831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare: 1.train \n",
    "    \"\"\"\n",
    "\n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    for seed in CFG.seed:\n",
    "        LOGGER.info(f\"========== seed{seed} ==========\")\n",
    "        seed_torch()\n",
    "\n",
    "        train = pd.read_csv('/home/yamanaka/Estimate_KIc_with_ViT/Mototake_Analysis/VGG+GP/inout_data.csv', header=None, names=['Id', 'KIc'])\n",
    "        train['file_path'] = ['/home/yamanaka/Estimate_KIc_with_ViT/Mototake_Analysis/VGG+GP/imagedata/' + str(i) + '.jpg' for i in train['Id']]\n",
    "        # train = pd.read_csv('../../KIc/Model/vgg/vgg16_Kfold_seed1_oof_df.csv')\n",
    "        # vit_oof = pd.read_csv('../../KIc/Model/vit/vit_large_patch32_224_Kfold_seed1_oof_df.csv')\\\n",
    "        #     .sort_values(by='Id').reset_index(drop=True)\n",
    "        # f = open(\"../../Mototake_Analysis/VGG+GP/Y_pred_rational.pkl\",\"rb\")\n",
    "        # plot_Y_rational = pkl.load(f)\n",
    "        # f.close()\n",
    "        # oof['VGG+GP_preds'] = plot_Y_rational[1][3]\n",
    "        # oof = oof.sort_values(by='Id').reset_index(drop=True)\n",
    "\n",
    "        # # diff definition\n",
    "        # oof['vgg_diff'] = abs(oof['preds'] - oof['KIc'])\n",
    "        # vit_oof['vit_diff'] = abs(vit_oof['preds'] - vit_oof['KIc'])\n",
    "        # vgg_gp = abs(oof['VGG+GP_preds'] - oof['KIc'])\n",
    "        # vit_oof['vit_diff_from_vgg'] = oof['vgg_diff'] - vit_oof['vit_diff']\n",
    "        # vit_oof['vit_absdiff_from_vgg'] = abs(oof['vgg_diff'] - vit_oof['vit_diff'])\n",
    "\n",
    "        if CFG.debug:\n",
    "            CFG.epochs = 1\n",
    "            train = train.sample(n=100, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "        if CFG.kfold == 'Kfold':\n",
    "            Fold = KFold(n_splits=CFG.n_fold, shuffle=True, random_state=seed)\n",
    "            for n, (train_index, val_index) in enumerate(Fold.split(train)):\n",
    "                train.loc[val_index, 'fold'] = int(n)\n",
    "            train['fold'] = train['fold'].astype(int)\n",
    "        elif CFG.kfold == \"StratifiedKfold\":\n",
    "            num_bins = int(np.floor(1 + np.log2(len(train))))\n",
    "            train[\"bins\"] = pd.cut(train[CFG.target_col], bins=num_bins, labels=False)\n",
    "            Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=seed)\n",
    "            for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"bins\"])):\n",
    "                train.loc[val_index, 'fold'] = int(n)\n",
    "            train['fold'] = train['fold'].astype(int)\n",
    "\n",
    "        # # train出力 vgg \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            # train.to_csv vggも\n",
    "            _oof_df = train_loop(train, fold, seed)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+f'{CFG.model_name}_{CFG.kfold}_seed{seed}_oof_df_netweight.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-09-25T01:39:32.080653Z",
     "iopub.status.busy": "2021-09-25T01:39:32.080395Z",
     "iopub.status.idle": "2021-09-25T01:43:14.486097Z",
     "shell.execute_reply": "2021-09-25T01:43:14.484211Z",
     "shell.execute_reply.started": "2021-09-25T01:39:32.080626Z"
    },
    "papermill": {
     "duration": 25805.563027,
     "end_time": "2021-08-04T08:35:35.784865",
     "exception": false,
     "start_time": "2021-08-04T01:25:30.221838",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== seed42 ==========\n",
      "========== seed42 ==========\n",
      "========== seed42 ==========\n",
      "========== fold: 0 training ==========\n",
      "========== fold: 0 training ==========\n",
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.5301(3.5301) \n",
      "EVAL: [2/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.7491(3.3912) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "========== fold: 0 result ==========\n",
      "========== fold: 0 result ==========\n",
      "Score: 3.4005\n",
      "Score: 3.4005\n",
      "Score: 3.4005\n",
      "========== fold: 1 training ==========\n",
      "========== fold: 1 training ==========\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.4645(3.4645) \n",
      "EVAL: [2/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.6869(3.3542) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "========== fold: 1 result ==========\n",
      "========== fold: 1 result ==========\n",
      "Score: 3.3614\n",
      "Score: 3.3614\n",
      "Score: 3.3614\n",
      "========== fold: 2 training ==========\n",
      "========== fold: 2 training ==========\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.3650(3.3650) \n",
      "EVAL: [2/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.5734(3.2679) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "========== fold: 2 result ==========\n",
      "========== fold: 2 result ==========\n",
      "Score: 3.2740\n",
      "Score: 3.2740\n",
      "Score: 3.2740\n",
      "========== fold: 3 training ==========\n",
      "========== fold: 3 training ==========\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.6398(3.6398) \n",
      "EVAL: [2/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.7505(3.4796) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "========== fold: 3 result ==========\n",
      "========== fold: 3 result ==========\n",
      "Score: 3.4872\n",
      "Score: 3.4872\n",
      "Score: 3.4872\n",
      "========== fold: 4 training ==========\n",
      "========== fold: 4 training ==========\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.4890(3.4890) \n",
      "EVAL: [2/3] Elapsed 0m 0s (remain 0m 0s) Loss: 3.4515(3.2229) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 result ==========\n",
      "========== fold: 4 result ==========\n",
      "========== fold: 4 result ==========\n",
      "Score: 3.2371\n",
      "Score: 3.2371\n",
      "Score: 3.2371\n",
      "========== CV ==========\n",
      "========== CV ==========\n",
      "========== CV ==========\n",
      "Score: 3.3533\n",
      "Score: 3.3533\n",
      "Score: 3.3533\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
